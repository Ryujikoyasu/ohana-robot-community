ここでは，植物解説・実況をロボットにさせながら散歩する方法を紹介する．

1. [Pl@ntnet](https://identify.plantnet.org/ja)が提供しているAPIを用いて，植物を同定し，
2. 同定した植物をOpenAI APIのGPT-4に解説させ，
3. OpenAI APIのTTSモデルで音声化する．

ポイントは精度とリアルタイム性．遅かったら使えない．UXの向上のために，最速で同定して，最速で音声を流す必要がある．
新体験さが重要なので同定ミスはOK.でも，デタラメはNG．
GPT-4VやGeminiといったLarge Multimodal Modelを用いた同定方法は，得意な種の傾向があると思われる．正解することもあるが，何より遅い．  
Google lensはかなり良いが，APIがない．  
Pl@ntnetだと，信頼できて，精度もそこそこ良く，早い．何より，データセットがオープンになっていて，一日500回の同定は無料という素晴らしさ．
これは同定される上位数十のリストがjson形式で得られる．  
そのスコア分布に従って，LLMの解説を変える（自信満々とか，自信なさげとか，抽象的な種や科だけいうとか）ことも考えたが，何よりプロンプトエンジニアリングが難しく，遅くなる．スコアをLLMに入れると，スコアを解説しがちだが，そんなのは聞き手にとってどうでも良いし，不自然である．

ということで，スコアがどれだけ低くても，最上位の植物名だけ抽出することにした．
意外とGPT-4は植物のことが詳しいみたい．なかなか楽しい解説が聞ける．
あとは，APIのストリーミングの機能を用いて，一文が生成されるごとにTTSのAPIに突っ込む．全文生成されるのを待って，全文の音声データを作っていては待ちくたびれる．

OpenAIのTTSは日本語が上手くないがそれも一興．GoogleやMetaAIのTTSも試したが，日本語は上手くない．
多分，Amazonが一番うまい気がする．探せば良いのあると思う．
